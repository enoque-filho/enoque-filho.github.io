[
  {
    "objectID": "projetos.html",
    "href": "projetos.html",
    "title": "Projetos",
    "section": "",
    "text": "Analise Exploratoria: loan_data\n\n\nEstudo de modelagem de classificação\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInferência Estatística Organizada: no R\n\n\n\n\n\n\n\n\n\n\n\nEnoque Filho\n\n\n\n\n\n\n\n\n\n\n\n\nClassificação por regressão logistica\n\n\n\n\n\n\nRegressão Logistica\n\nGLM\n\nR\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAtividade Regressão Logistica\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2024\n\n\nEnoque Filho\n\n\n\n\n\n\n\n\n\n\n\n\nSpotify 2023: Análise das músicas mais populares\n\n\n\n\n\n\nEDA\n\nkaggle\n\nR\n\nAnálise Descritiva\n\n\n\n\n\n\n\n\n\nDec 21, 2023\n\n\nEnoque Filho\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sobre mim",
    "section": "",
    "text": "Estatística | Analise de Dados\nR, Excel, Power BI, Power Query.\nExcel\nPacote Office\nInglês: Intermediário"
  },
  {
    "objectID": "index.html#um-pouco-mais-sobre-mim",
    "href": "index.html#um-pouco-mais-sobre-mim",
    "title": "enoque-filho",
    "section": "Um pouco mais sobre mim:",
    "text": "Um pouco mais sobre mim:\nEu tenho interesse em ciência, pesquisa, psciologia , psicometria, data science, programação, linguagem R e tidyverse.\nDentre os serviços que gostaria de oferecer a estudantes de graduação, pos graduação e e pesquisadores no geral estão:\n\nAnálise Descritiva\nAnálise Exloratória de Dados\nModelagem Estatística\nMentoria\n\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "index.html#contatos",
    "href": "index.html#contatos",
    "title": "Pagina Incial",
    "section": "Contatos:",
    "text": "Contatos:\n\nWhatsApp: (86) 99431-1263\nGmail: enoquefilho@gmail.com\nLinkedIn: &lt;linkedin.com/in/enoque-filho-70200b183&gt;\nGithub: https://github.com/enoque-filho\nInstagram: @enokesan"
  },
  {
    "objectID": "index.html#sobre-mim",
    "href": "index.html#sobre-mim",
    "title": "Pagina Incial",
    "section": "",
    "text": "Me chamo Enoque Filho, sou graduando do curso de Bacharelado Em Estatística na Universidade Federal do Piauí (UFPI) com espectativas de concluir em 2024.\nTenho interesse por Estatística, Metodologia Cientifica, Psicologia, Psicometria, Programação, Linguagem R. tidyverse, R Markdown e Quarto."
  },
  {
    "objectID": "index.html#minhas-habilidades",
    "href": "index.html#minhas-habilidades",
    "title": "Pagina Incial",
    "section": "Minhas habilidades",
    "text": "Minhas habilidades\n\nLinguagem R: Avançado\nExcel: Intermediário\nInglês: Intermediário"
  },
  {
    "objectID": "index.html#resumo-de-habilidades",
    "href": "index.html#resumo-de-habilidades",
    "title": "Sobre mim",
    "section": "Resumo de Habilidades",
    "text": "Resumo de Habilidades\n\nEstatística | Analise de Dados\nR (Linguagem de Programação) Avançado\nExcel\nPacote Office\nInglês: Intermediário"
  },
  {
    "objectID": "index.html#entre-em-contato",
    "href": "index.html#entre-em-contato",
    "title": "Sobre mim",
    "section": "Entre em contato",
    "text": "Entre em contato\n\n: (86) 99431-1263\n: enoquefilhomail@gmail.com"
  },
  {
    "objectID": "index.html#quem-sou",
    "href": "index.html#quem-sou",
    "title": "Sobre mim",
    "section": "Quem Sou",
    "text": "Quem Sou\nMe chamo Enoque, sou formado em Em Estatística pela Universidade Federal do Piauí (UFPI).\nTenho interesse por Estatística, Ciência, Análise e Ciência de Dados. Estou a procura de experência profissional."
  },
  {
    "objectID": "index.html#formação",
    "href": "index.html#formação",
    "title": "Sobre mim",
    "section": "Formação",
    "text": "Formação\n\nBacharelado em Estatística pela UFPI | 2019 - 2024"
  },
  {
    "objectID": "projetos.html#projetos",
    "href": "projetos.html#projetos",
    "title": "Projetos",
    "section": "",
    "text": "Por vir"
  },
  {
    "objectID": "projetos.html#notebooks-no-kaggle.com",
    "href": "projetos.html#notebooks-no-kaggle.com",
    "title": "Projetos",
    "section": "",
    "text": "https://www.kaggle.com/enoquefilho"
  },
  {
    "objectID": "posts/proj - eda-spotify-2023/index.html",
    "href": "posts/proj - eda-spotify-2023/index.html",
    "title": "Spotify 2023: Análise das músicas mais populares",
    "section": "",
    "text": "Código\n# pacotes = c('tidyverse', 'gt', 'reactable')\n# enoqueR_dependencias = c(\"tidyverse\", \"gtsummary\", \"pryr\", \"rstatix\", \"moments\")\n# install.packages(c(pacotes, enoqueR_dependencias))\n# remotes::install_github('enoqueR/enoqueR)\n\nlibrary(tidyverse)\nlibrary(enoqueR) \nlibrary(gt)\nlibrary(reactable)\n\n\n\n\n\n\nThis dataset contains a comprehensive list of the most famous songs of 2023 as listed on Spotify. The dataset offers a wealth of features beyond what is typically available in similar datasets. It provides insights into each song’s attributes, popularity, and presence on various music platforms. The dataset includes information such as track name, artist(s) name, release date, Spotify playlists and charts, streaming statistics, Apple Music presence, Deezer presence, Shazam charts, and various audio features. - Fonte: https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023\n\n\n\nCódigo\n# carregando o conjunto de dados\n# disponivel em: https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023\n\ndados &lt;- \n  readr::read_csv('spotify-2023.csv') %&gt;% \n  janitor::clean_names()\n\ndados %&gt;% head(30)\n\n\n\n\n  \n\n\n\n\n\nCódigo\nbind_rows(\n  dados %&gt;% enoqueR::overall_info(),\n  dados %&gt;% enoqueR::overall_tipos()\n)\n\n\n\n?(caption)\n\n\n\n\n\n  \n\n\n\n\n\nO conjunto de dados apresenta um total de 24 colunas, 955 observações e ausência de linhas duplicadas. Dentre as 24 colunas, 19 são numéricas e 5 são de caractere.\n\n\nCódigo\ndados %&gt;% glimpse()\n\n\nRows: 953\nColumns: 24\n$ track_name               &lt;chr&gt; \"Seven (feat. Latto) (Explicit Ver.)\", \"LALA\"…\n$ artist_s_name            &lt;chr&gt; \"Latto, Jung Kook\", \"Myke Towers\", \"Olivia Ro…\n$ artist_count             &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, …\n$ released_year            &lt;dbl&gt; 2023, 2023, 2023, 2019, 2023, 2023, 2023, 202…\n$ released_month           &lt;dbl&gt; 7, 3, 6, 8, 5, 6, 3, 7, 5, 3, 4, 7, 1, 4, 3, …\n$ released_day             &lt;dbl&gt; 14, 23, 30, 23, 18, 1, 16, 7, 15, 17, 17, 7, …\n$ in_spotify_playlists     &lt;dbl&gt; 553, 1474, 1397, 7858, 3133, 2186, 3090, 714,…\n$ in_spotify_charts        &lt;dbl&gt; 147, 48, 113, 100, 50, 91, 50, 43, 83, 44, 40…\n$ streams                  &lt;dbl&gt; 141381703, 133716286, 140003974, 800840817, 3…\n$ in_apple_playlists       &lt;dbl&gt; 43, 48, 94, 116, 84, 67, 34, 25, 60, 49, 41, …\n$ in_apple_charts          &lt;dbl&gt; 263, 126, 207, 207, 133, 213, 222, 89, 210, 1…\n$ in_deezer_playlists      &lt;dbl&gt; 45, 58, 91, 125, 87, 88, 43, 30, 48, 66, 54, …\n$ in_deezer_charts         &lt;dbl&gt; 10, 14, 14, 12, 15, 17, 13, 13, 11, 13, 12, 5…\n$ in_shazam_charts         &lt;dbl&gt; 826, 382, 949, 548, 425, 946, 418, 194, 953, …\n$ bpm                      &lt;dbl&gt; 125, 92, 138, 170, 144, 141, 148, 100, 130, 1…\n$ key                      &lt;chr&gt; \"B\", \"C#\", \"F\", \"A\", \"A\", \"C#\", \"F\", \"F\", \"C#…\n$ mode                     &lt;chr&gt; \"Major\", \"Major\", \"Major\", \"Major\", \"Minor\", …\n$ danceability_percent     &lt;dbl&gt; 80, 71, 51, 55, 65, 92, 67, 67, 85, 81, 57, 7…\n$ valence_percent          &lt;dbl&gt; 89, 61, 32, 58, 23, 66, 83, 26, 22, 56, 56, 5…\n$ energy_percent           &lt;dbl&gt; 83, 74, 53, 72, 80, 58, 76, 71, 62, 48, 72, 8…\n$ acousticness_percent     &lt;dbl&gt; 31, 7, 17, 11, 14, 19, 48, 37, 12, 21, 23, 18…\n$ instrumentalness_percent &lt;dbl&gt; 0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ liveness_percent         &lt;dbl&gt; 8, 10, 31, 11, 11, 8, 8, 11, 28, 8, 27, 15, 3…\n$ speechiness_percent      &lt;dbl&gt; 4, 4, 6, 15, 6, 24, 3, 4, 9, 33, 5, 7, 7, 3, …\n\n\n\nstreams aparece como variável character apesar de apresentar observações numéricas e parece representar uma contagem\nUma inspeção nas observações da variável streams revelou uma observação contendo um possivel erro de nessa observação. Tal erro foi subtituido por um valor ausente e então os dados foram importados novamente.\n\n\n\nCódigo\ndados %&gt;% \n  enoqueR::dataset_var_info() %&gt;% \n  as_tibble() %&gt;% \n  arrange(tipo, n_distinct) %&gt;% \n  gt() %&gt;% \n  fmt_number(columns = 6:7)\n\n\n\n\n\n\n  \n    \n      variavel\n      tipo\n      n\n      n_miss\n      n_distinct\n      w\n      p\n    \n  \n  \n    mode\ncharacter\n953\n0\n2\nNA\nNA\n    key\ncharacter\n858\n95\n12\nNA\nNA\n    artist_s_name\ncharacter\n953\n0\n645\nNA\nNA\n    track_name\ncharacter\n953\n0\n943\nNA\nNA\n    artist_count\nnumeric\n953\n0\n8\n0.64\n0.00\n    released_month\nnumeric\n953\n0\n12\n0.93\n0.00\n    released_day\nnumeric\n953\n0\n31\n0.94\n0.00\n    in_deezer_charts\nnumeric\n953\n0\n34\n0.50\n0.00\n    instrumentalness_percent\nnumeric\n953\n0\n39\n0.19\n0.00\n    speechiness_percent\nnumeric\n953\n0\n48\n0.71\n0.00\n    released_year\nnumeric\n953\n0\n50\n0.43\n0.00\n    liveness_percent\nnumeric\n953\n0\n68\n0.77\n0.00\n    danceability_percent\nnumeric\n953\n0\n72\n0.98\n0.00\n    energy_percent\nnumeric\n953\n0\n80\n0.98\n0.00\n    in_spotify_charts\nnumeric\n953\n0\n82\n0.67\n0.00\n    valence_percent\nnumeric\n953\n0\n94\n0.98\n0.00\n    acousticness_percent\nnumeric\n953\n0\n98\n0.87\n0.00\n    bpm\nnumeric\n953\n0\n124\n0.98\n0.00\n    in_apple_charts\nnumeric\n953\n0\n172\n0.88\n0.00\n    in_shazam_charts\nnumeric\n903\n50\n199\n0.41\n0.00\n    in_apple_playlists\nnumeric\n953\n0\n234\n0.72\n0.00\n    in_deezer_playlists\nnumeric\n953\n0\n348\n0.36\n0.00\n    in_spotify_playlists\nnumeric\n953\n0\n879\n0.62\n0.00\n    streams\nnumeric\n952\n1\n949\n0.76\n0.00\n  \n  \n  \n\n\n\n\n\nNenhuma das varíaveis numéricas apresenta distribuição normal.\nDas 145 celulas vazias ?@tbl-overall 95 se encontram na coluna key e e 50 na coluna `in_shazam_charts.\nA variável track_name não é suficiente para servir de nome para as observações (945 != 955).\nAs colunas track_name, artist_s_name e streamsapresentam valores distintos elevados. Deve ser buscar abordar tais colunas como caracteristica de denominação de cada observação.\nAs demais colunas de caractere (keye mode) podem ser consideradas fatores\ncolunas de data podem ser transformadas em uma coluna única\n\n\n\nCódigo\ndados = dados %&gt;% \n  mutate(\n    key = as.factor(key),\n    mode = as.factor(mode),\n    release_date = as_date(paste0(released_year,'-',released_month,'-',released_day))\n  )"
  },
  {
    "objectID": "posts/proj - eda-spotify-2023/index.html#setup",
    "href": "posts/proj - eda-spotify-2023/index.html#setup",
    "title": "Spotify 2023: Análise das músicas mais populares",
    "section": "",
    "text": "Código\n# pacotes = c('tidyverse', 'gt', 'reactable')\n# enoqueR_dependencias = c(\"tidyverse\", \"gtsummary\", \"pryr\", \"rstatix\", \"moments\")\n# install.packages(c(pacotes, enoqueR_dependencias))\n# remotes::install_github('enoqueR/enoqueR)\n\nlibrary(tidyverse)\nlibrary(enoqueR) \nlibrary(gt)\nlibrary(reactable)"
  },
  {
    "objectID": "posts/proj - eda-spotify-2023/index.html#conjunto-de-dados",
    "href": "posts/proj - eda-spotify-2023/index.html#conjunto-de-dados",
    "title": "Spotify 2023: Análise das músicas mais populares",
    "section": "",
    "text": "This dataset contains a comprehensive list of the most famous songs of 2023 as listed on Spotify. The dataset offers a wealth of features beyond what is typically available in similar datasets. It provides insights into each song’s attributes, popularity, and presence on various music platforms. The dataset includes information such as track name, artist(s) name, release date, Spotify playlists and charts, streaming statistics, Apple Music presence, Deezer presence, Shazam charts, and various audio features. - Fonte: https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023\n\n\n\nCódigo\n# carregando o conjunto de dados\n# disponivel em: https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023\n\ndados &lt;- \n  readr::read_csv('spotify-2023.csv') %&gt;% \n  janitor::clean_names()\n\ndados %&gt;% head(30)\n\n\n\n\n  \n\n\n\n\n\nCódigo\nbind_rows(\n  dados %&gt;% enoqueR::overall_info(),\n  dados %&gt;% enoqueR::overall_tipos()\n)\n\n\n\n?(caption)\n\n\n\n\n\n  \n\n\n\n\n\nO conjunto de dados apresenta um total de 24 colunas, 955 observações e ausência de linhas duplicadas. Dentre as 24 colunas, 19 são numéricas e 5 são de caractere.\n\n\nCódigo\ndados %&gt;% glimpse()\n\n\nRows: 953\nColumns: 24\n$ track_name               &lt;chr&gt; \"Seven (feat. Latto) (Explicit Ver.)\", \"LALA\"…\n$ artist_s_name            &lt;chr&gt; \"Latto, Jung Kook\", \"Myke Towers\", \"Olivia Ro…\n$ artist_count             &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, …\n$ released_year            &lt;dbl&gt; 2023, 2023, 2023, 2019, 2023, 2023, 2023, 202…\n$ released_month           &lt;dbl&gt; 7, 3, 6, 8, 5, 6, 3, 7, 5, 3, 4, 7, 1, 4, 3, …\n$ released_day             &lt;dbl&gt; 14, 23, 30, 23, 18, 1, 16, 7, 15, 17, 17, 7, …\n$ in_spotify_playlists     &lt;dbl&gt; 553, 1474, 1397, 7858, 3133, 2186, 3090, 714,…\n$ in_spotify_charts        &lt;dbl&gt; 147, 48, 113, 100, 50, 91, 50, 43, 83, 44, 40…\n$ streams                  &lt;dbl&gt; 141381703, 133716286, 140003974, 800840817, 3…\n$ in_apple_playlists       &lt;dbl&gt; 43, 48, 94, 116, 84, 67, 34, 25, 60, 49, 41, …\n$ in_apple_charts          &lt;dbl&gt; 263, 126, 207, 207, 133, 213, 222, 89, 210, 1…\n$ in_deezer_playlists      &lt;dbl&gt; 45, 58, 91, 125, 87, 88, 43, 30, 48, 66, 54, …\n$ in_deezer_charts         &lt;dbl&gt; 10, 14, 14, 12, 15, 17, 13, 13, 11, 13, 12, 5…\n$ in_shazam_charts         &lt;dbl&gt; 826, 382, 949, 548, 425, 946, 418, 194, 953, …\n$ bpm                      &lt;dbl&gt; 125, 92, 138, 170, 144, 141, 148, 100, 130, 1…\n$ key                      &lt;chr&gt; \"B\", \"C#\", \"F\", \"A\", \"A\", \"C#\", \"F\", \"F\", \"C#…\n$ mode                     &lt;chr&gt; \"Major\", \"Major\", \"Major\", \"Major\", \"Minor\", …\n$ danceability_percent     &lt;dbl&gt; 80, 71, 51, 55, 65, 92, 67, 67, 85, 81, 57, 7…\n$ valence_percent          &lt;dbl&gt; 89, 61, 32, 58, 23, 66, 83, 26, 22, 56, 56, 5…\n$ energy_percent           &lt;dbl&gt; 83, 74, 53, 72, 80, 58, 76, 71, 62, 48, 72, 8…\n$ acousticness_percent     &lt;dbl&gt; 31, 7, 17, 11, 14, 19, 48, 37, 12, 21, 23, 18…\n$ instrumentalness_percent &lt;dbl&gt; 0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ liveness_percent         &lt;dbl&gt; 8, 10, 31, 11, 11, 8, 8, 11, 28, 8, 27, 15, 3…\n$ speechiness_percent      &lt;dbl&gt; 4, 4, 6, 15, 6, 24, 3, 4, 9, 33, 5, 7, 7, 3, …\n\n\n\nstreams aparece como variável character apesar de apresentar observações numéricas e parece representar uma contagem\nUma inspeção nas observações da variável streams revelou uma observação contendo um possivel erro de nessa observação. Tal erro foi subtituido por um valor ausente e então os dados foram importados novamente.\n\n\n\nCódigo\ndados %&gt;% \n  enoqueR::dataset_var_info() %&gt;% \n  as_tibble() %&gt;% \n  arrange(tipo, n_distinct) %&gt;% \n  gt() %&gt;% \n  fmt_number(columns = 6:7)\n\n\n\n\n\n\n  \n    \n      variavel\n      tipo\n      n\n      n_miss\n      n_distinct\n      w\n      p\n    \n  \n  \n    mode\ncharacter\n953\n0\n2\nNA\nNA\n    key\ncharacter\n858\n95\n12\nNA\nNA\n    artist_s_name\ncharacter\n953\n0\n645\nNA\nNA\n    track_name\ncharacter\n953\n0\n943\nNA\nNA\n    artist_count\nnumeric\n953\n0\n8\n0.64\n0.00\n    released_month\nnumeric\n953\n0\n12\n0.93\n0.00\n    released_day\nnumeric\n953\n0\n31\n0.94\n0.00\n    in_deezer_charts\nnumeric\n953\n0\n34\n0.50\n0.00\n    instrumentalness_percent\nnumeric\n953\n0\n39\n0.19\n0.00\n    speechiness_percent\nnumeric\n953\n0\n48\n0.71\n0.00\n    released_year\nnumeric\n953\n0\n50\n0.43\n0.00\n    liveness_percent\nnumeric\n953\n0\n68\n0.77\n0.00\n    danceability_percent\nnumeric\n953\n0\n72\n0.98\n0.00\n    energy_percent\nnumeric\n953\n0\n80\n0.98\n0.00\n    in_spotify_charts\nnumeric\n953\n0\n82\n0.67\n0.00\n    valence_percent\nnumeric\n953\n0\n94\n0.98\n0.00\n    acousticness_percent\nnumeric\n953\n0\n98\n0.87\n0.00\n    bpm\nnumeric\n953\n0\n124\n0.98\n0.00\n    in_apple_charts\nnumeric\n953\n0\n172\n0.88\n0.00\n    in_shazam_charts\nnumeric\n903\n50\n199\n0.41\n0.00\n    in_apple_playlists\nnumeric\n953\n0\n234\n0.72\n0.00\n    in_deezer_playlists\nnumeric\n953\n0\n348\n0.36\n0.00\n    in_spotify_playlists\nnumeric\n953\n0\n879\n0.62\n0.00\n    streams\nnumeric\n952\n1\n949\n0.76\n0.00\n  \n  \n  \n\n\n\n\n\nNenhuma das varíaveis numéricas apresenta distribuição normal.\nDas 145 celulas vazias ?@tbl-overall 95 se encontram na coluna key e e 50 na coluna `in_shazam_charts.\nA variável track_name não é suficiente para servir de nome para as observações (945 != 955).\nAs colunas track_name, artist_s_name e streamsapresentam valores distintos elevados. Deve ser buscar abordar tais colunas como caracteristica de denominação de cada observação.\nAs demais colunas de caractere (keye mode) podem ser consideradas fatores\ncolunas de data podem ser transformadas em uma coluna única\n\n\n\nCódigo\ndados = dados %&gt;% \n  mutate(\n    key = as.factor(key),\n    mode = as.factor(mode),\n    release_date = as_date(paste0(released_year,'-',released_month,'-',released_day))\n  )"
  },
  {
    "objectID": "posts/proj - eda-spotify-2023/index.html#análise-visual-univariada",
    "href": "posts/proj - eda-spotify-2023/index.html#análise-visual-univariada",
    "title": "Spotify 2023: Análise das músicas mais populares",
    "section": "Análise visual univariada",
    "text": "Análise visual univariada\n\n\nCódigo\ndados %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \n    drop_na() %&gt;% \n  ggplot(aes(x = value)) + \n  geom_histogram(color = 'white', fill = 'green4') + \n  facet_wrap(~name, scales = 'free') + \n  theme_test()\n\n\n\n\n\n\n\nCódigo\ndados %&gt;% \n  select(where(is.numeric)) %&gt;% \n  select(starts_with('in_'), contains('percent')) %&gt;% \n  pivot_longer(everything()) %&gt;% \n  mutate(tipo = ifelse(str_detect(name, 'percent'), 'song info', 'app info')) %&gt;% \n  ggplot(aes(x = name, y = value)) +\n  geom_boxplot(color = 'green4')  + \n  theme_test() + \n  facet_wrap(~tipo, scales = 'free', ncol = 1) + \n  coord_flip()\n\n\n\n\n\n\n\nCódigo\n# dados %&gt;% \n#   select(where(is.factor)) %&gt;% \n#   names() %&gt;% \n#   map(.f = function(x){\n#     tibble(\"{{x}}\" := dados %&gt;% pull({{x}})) %&gt;% \n#   })\n\n\n\n\nCódigo\ndados %&gt;% \n  mutate(key = factor(key, levels = c(\"C#\", \"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"))) %&gt;% \n  select(where(is.factor)) %&gt;% \n  pivot_longer(everything()) %&gt;% \n  count(name, value) %&gt;% \n  ggplot(aes(x = value, y = n)) + \n  geom_col(color = 'gray50', alpha = 0.5) +\n  facet_wrap(~name, ncol = 2, scales ='free') + \n  theme_test()"
  },
  {
    "objectID": "posts/proj - eda-spotify-2023/index.html#anláise-bidimensional",
    "href": "posts/proj - eda-spotify-2023/index.html#anláise-bidimensional",
    "title": "Spotify 2023: Análise das músicas mais populares",
    "section": "Anláise bidimensional",
    "text": "Anláise bidimensional\n\n\nCódigo\ndados %&gt;% \n  select(bpm, contains('percent'), starts_with('in')) %&gt;% \n  drop_na() %&gt;% \n  cor(method = 'spearman') %&gt;% \n  reshape2::melt() %&gt;% \n  ggplot(aes(x = Var2, y = Var1, fill = value, label = round(value, 2))) + \n  geom_tile() + \n  theme_minimal() + \n  scale_fill_gradient2(low = 'blue3', mid = 'lightyellow', high = 'red',midpoint = 0) + \n  theme(axis.text.x = element_text(angle = 90)) +\n  labs(fill = 'Spearman') + \n  geom_text(color = 'black')\n\n\n\n\n\n\nAs variáveis relacionadas a contagem de presença das músicas em charts e playlists de diferentes serviços de streaming de música apresentaram correalações positivas que variam ao redor de 0.5 de correlação. in_deezer_playlists & in_spotify_playlists apresentaram a maior correlação positiva (0.84) e acousticness_percent & energy_percent a maior correlação negativa (-0.46)."
  },
  {
    "objectID": "enoque-cv.html",
    "href": "enoque-cv.html",
    "title": "ENOQUE DE SOUSA DA ANUCIAÇÃO FILHO",
    "section": "",
    "text": "Ganhar experiência profissional\nDesenvolver, a partir da prática e observação, noções de empreendedorismo e de como se portar como profissional competente.\nAuxiliar os profissionais de outras áreas a resolver problemas e alcançar bons resultados."
  },
  {
    "objectID": "enoque-cv.html#inglês",
    "href": "enoque-cv.html#inglês",
    "title": "ENOQUE DE SOUSA DA ANUCIAÇÃO FILHO",
    "section": "Inglês:",
    "text": "Inglês:\n\nLeitura: Bom\nEscrita: Razoável\nFala: Pouco"
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html",
    "href": "posts/proj - reg-logistica/index.html",
    "title": "Atividade Regressão Logistica",
    "section": "",
    "text": "O objetivo desse trabalho foi aplicar o método de regressão logistica em um conjunto de dados contendo uma variável binária (Sobreivente | Não sobrevivente) e outras variáveis independentes (Sexo, Classe e Idade)."
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html#importação-dos-dados",
    "href": "posts/proj - reg-logistica/index.html#importação-dos-dados",
    "title": "Atividade Regressão Logistica",
    "section": "IMPORTAÇÃO DOS DADOS",
    "text": "IMPORTAÇÃO DOS DADOS\nApós a importação dos dados as variáveis qualitativas foram recategorizadas, adicionando seus respectivies níveis.\n\nCódigodados &lt;-  \n  read.csv(\"dados.csv\", sep = '\\t') %&gt;% \n  mutate(\n    sobrevivente = factor(ifelse(sobrevivente == 0, \"Não\", \"Sim\"),\n                          levels = c(\"Sim\", \"Não\")),  # ordem dos níveis\n    sexo = factor(ifelse(sexo == 0, \"Feminino\",  \"Masculino\"),\n                  levels = c(\"Feminino\",\"Masculino\")), # ordem dos níveis\n    classe = factor(\n      case_when(\n        classe == 1 ~ \"Alta\",\n        classe == 2 ~ \"Média\",\n        classe == 3 ~ \"Baixa\",),\n      levels = c(\"Alta\", \"Média\", \"Baixa\")) # ordem dos níveis\n    )\n\n\nA variavel dependente será Sobrevivente tendo como nível de refererência o Sim. Portanto o modelo será ajustado para estimar razão de chances de Sobrevivência Não / Sobrevivencia Sim."
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html#análise-descritiva",
    "href": "posts/proj - reg-logistica/index.html#análise-descritiva",
    "title": "Atividade Regressão Logistica",
    "section": "ANÁLISE DESCRITIVA",
    "text": "ANÁLISE DESCRITIVA\n\nCódigoplot_sobrevivente &lt;-  dados %&gt;% \n  count(sobrevivente) %&gt;% \n  mutate(lab = paste0(n,' (', round(prop.table(n)*100, 2), '%)')) %&gt;%\n  ggplot(aes(x = sobrevivente, y = n, label = lab)) +\n  geom_col(fill = 'darkgreen', alpha = 0.6) +\n  geom_text(vjust = -0.5, size = 3) +\n  labs(y = 'Frequência')\n\nplot_sexo &lt;-  dados %&gt;% \n  count(sexo) %&gt;% \n  mutate(lab = paste0(n,' (', round(prop.table(n)*100, 2), '%)')) %&gt;%\n  ggplot(aes(x = sexo, y = n, label = lab)) +\n  geom_col(fill = 'darkgreen', alpha = 0.6) +\n  geom_text(vjust = -0.5, size = 3) +\n  labs(y = 'Frequência')\n\nplot_classe &lt;-  dados %&gt;% \n  count(classe) %&gt;% \n  mutate(lab = paste0(n,' (', round(prop.table(n)*100, 2), '%)')) %&gt;%\n  ggplot(aes(x = classe, y = n, label = lab)) +\n  geom_col(fill = 'darkgreen', alpha = 0.6) +\n  geom_text(vjust = -0.5, size = 3) +\n  labs(y = 'Frequência')\n\nplot_sobrevivente + plot_sexo + plot_classe\n\n\n\n\n\n\n\n\nCódigo  p1 &lt;- ggplot(dados, aes(y = '', x =  idade)) +\n    geom_boxplot(fill = \"gray70\", alpha = 0.5) +\n    theme(axis.ticks.x = element_blank(),\n          axis.text.y  = element_blank(),\n          axis.ticks.y = element_blank(),\n          axis.text    = element_blank(),\n          axis.title.x = element_blank()\n    ) +\n    labs(y = '')\n\n  p2 &lt;- ggplot(dados, aes(x = idade, after_stat(density))) +\n    geom_histogram(color = \"white\", fill = \"gray70\", bins = 30, alpha = 0.5) +\n    geom_density(color = \"black\", linewidth = 0.5) +\n    geom_vline(aes(xintercept = mean(   idade, na.rm = TRUE)),\n               linetype = 'dashed', color = 'red', linewidth = 0.8) +\n    labs(y = 'Densidade')\n\n\n  (p1 / p2) + \n    plot_layout(heights = c(1,5)) &\n    scale_x_continuous(\n      limits = c(min(pull(dados, idade), na.rm = TRUE) - 3,\n                 max(pull(dados, idade), na.rm = TRUE) + 3)\n      )\n\n\n\n\n\n\n\n\nCódigodados %&gt;% \n  gtsummary::tbl_cross(\n    sexo, sobrevivente, \n    statistic = \"{n} ({p}%)\",\n    percent = \"column\"\n    ) %&gt;% \n  bold_labels() %&gt;% \n  as_flex_table()\n\n\n\n\n\n\n \nsobrevivente\n \n\n\n\nSim\nNão\nTotal\n\n\n\n\nsexo\n\n\n\n\n\nFeminino\n292 (68%)\n96 (16%)\n388 (37%)\n\n\nMasculino\n135 (32%)\n523 (84%)\n658 (63%)\n\n\nTotal\n427 (100%)\n619 (100%)\n1,046 (100%)\n\n\n\n\n\n\n\nCódigocount(dados, sexo, sobrevivente) %&gt;% \n  ggbarplot(y = \"n\", x = \"sexo\", fill = \"sobrevivente\", \n            position = position_fill(), label = TRUE, lab.pos = \"in\", \n            orientation = \"horizontal\", lab.hjust = 1.6)\n\n\n\n\n\n\n\n\nCódigodados %&gt;% \n  gtsummary::tbl_cross(\n    classe, sobrevivente, \n    statistic = \"{n} ({p}%)\",\n    percent = \"column\"\n    ) %&gt;% \n  bold_labels() %&gt;% \n  as_flex_table()\n\n\n\n\n\n\n \nsobrevivente\n \n\n\n\nSim\nNão\nTotal\n\n\n\n\nclasse\n\n\n\n\n\nAlta\n181 (42%)\n103 (17%)\n284 (27%)\n\n\nMédia\n115 (27%)\n146 (24%)\n261 (25%)\n\n\nBaixa\n131 (31%)\n370 (60%)\n501 (48%)\n\n\nTotal\n427 (100%)\n619 (100%)\n1,046 (100%)\n\n\n\n\n\n\n\nCódigocount(dados, classe, sobrevivente) %&gt;% \n  ggbarplot(y = \"n\", x = \"classe\", \n            fill = \"sobrevivente\", position = position_fill(), \n            label = TRUE, lab.pos = \"in\", lab.hjust = 1.6,\n            orientation = \"horizontal\")\n\n\n\n\n\n\n\n\nCódigoggviolin(\n  dados,\n  x = \"sobrevivente\", \n  y = \"idade\", orientation = \"horizontal\", \n  fill = \"sobrevivente\", \n  add = \"boxplot\"\n  )"
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html#modelagem",
    "href": "posts/proj - reg-logistica/index.html#modelagem",
    "title": "Atividade Regressão Logistica",
    "section": "MODELAGEM",
    "text": "MODELAGEM\nAjustes de diferentes modelos\nModelo completo e modelo escolhido pelo método stepwise\n\nCódigo# Modelo com todas as variáveis\n  modelo_completo &lt;- glm(\n    data = dados, \n    formula = sobrevivente ~ ., \n    family = binomial()\n    )\n\n# Modelo stepwise\n  modelo_step &lt;- modelo_completo %&gt;% step()\n\nStart:  AIC=992.45\nsobrevivente ~ sexo + idade + classe\n\n         Df Deviance     AIC\n&lt;none&gt;        982.45  992.45\n- idade   1  1013.80 1021.80\n- classe  2  1101.34 1107.34\n- sexo    1  1255.69 1263.69\n\n\nCritério para selecionar o melhor modelo.\nO método stepwise apontou para o modelo completo.\n\nCódigolist(modelo_completo, modelo_step) %&gt;% \n  map(.f = function(x){\n    broom::glance(x) %&gt;% \n      select(AIC, BIC, Deviance = deviance)\n    }) %&gt;% \n  bind_rows() %&gt;% \n  mutate(.before = 1, \n         Modelo = c(\"modelo_completo\",\"modelo_step\")) %&gt;% \n  arrange(AIC) %&gt;% \n  flextable() %&gt;% \n  bold(i = 1, part = \"header\") %&gt;% \n  autofit()\n\n\n\n\n\nModelo\nAIC\nBIC\nDeviance\n\n\n\nmodelo_completo\n992.4531\n1,017.217\n982.4531\n\n\nmodelo_step\n992.4531\n1,017.217\n982.4531"
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html#diagnóstico-do-modelo",
    "href": "posts/proj - reg-logistica/index.html#diagnóstico-do-modelo",
    "title": "Atividade Regressão Logistica",
    "section": "DIAGNÓSTICO DO MODELO",
    "text": "DIAGNÓSTICO DO MODELO\n\nCódigotabela_modelo = \ntbl_regression(modelo_completo, exponentiate = TRUE) %&gt;%\n    add_glance_table(\n          include = c(AIC, BIC, deviance))  %&gt;%\n    modify_column_unhide(column = std.error) %&gt;% \n  bold_labels() %&gt;% \n  as_flex_table()\n\ntabela_modelo\n\n\n\n\n\nCaracterísticas\nOR\nSE\n95% IC\nValor-p\n\n\n\nsexo\n\n\n\n\n\n\nFeminino\n—\n—\n—\n\n\n\nMasculino\n12.2\n0.166\n8.83, 16.9\n&lt;0.001\n\n\nidade\n1.03\n0.006\n1.02, 1.05\n&lt;0.001\n\n\nclasse\n\n\n\n\n\n\nAlta\n—\n—\n—\n\n\n\nMédia\n3.60\n0.226\n2.32, 5.63\n&lt;0.001\n\n\nBaixa\n9.87\n0.226\n6.39, 15.5\n&lt;0.001\n\n\nAIC\n992\n\n\n\n\n\nBIC\n1,017\n\n\n\n\n\nDeviance\n982\n\n\n\n\n\nAbreviações: IC = Intervalo de Confiança, OR = Razão de chances, SE = Erro padrão\n\n\n\n\n\nAnálise de Deviance\n\nCódigoanova(modelo_completo, test = \"Chisq\") %&gt;% \n  tidy() %&gt;%\n  mutate(p.value = scales::pvalue(p.value)) %&gt;% \n  flextable() %&gt;% \n  bold(part = \"header\") %&gt;% \n  colformat_double(j = 3:5, digits = 3)\n\n\n\n\n\nterm\ndf\ndeviance\ndf.residual\nresidual.deviance\np.value\n\n\n\nNULL\n\n\n1,045\n1,414.620\n\n\n\nsexo\n1\n312.612\n1,044\n1,102.008\n&lt;0.001\n\n\nidade\n1\n0.669\n1,043\n1,101.339\n0.413\n\n\nclasse\n2\n118.886\n1,041\n982.453\n&lt;0.001\n\n\n\n\n\n\nAnálise de Residuos\nPacote performance\nAutocorrelação\n\nCódigomodelo_completo %&gt;% performance::check_autocorrelation()\n\nOK: Residuals appear to be independent and not autocorrelated (p = 0.062).\n\n\nOutliers\n\nCódigomodelo_completo %&gt;% performance::check_outliers()\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.5).\n- For variable: (Whole model)\n\n\nMulticolinearidade\n\nCódigomodelo_completo %&gt;% performance::check_collinearity()\n\n# Check for Multicollinearity\n\nLow Correlation\n\n   Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n   sexo 1.05 [1.01, 1.19]     1.03      0.95     [0.84, 0.99]\n  idade 1.35 [1.26, 1.47]     1.16      0.74     [0.68, 0.79]\n classe 1.41 [1.32, 1.54]     1.19      0.71     [0.65, 0.76]\n\n\nTeste de resíduos\n\nCódigo# Resíduos de Pearson\ntibble(\n  Pearson = residuals(modelo_completo, type = \"pearson\"),\n  Deviance = residuals(modelo_completo, type = \"deviance\"),\n) %&gt;% \n  pivot_longer(everything(), names_to = \"Residuo\") %&gt;% \n  summarise(SQR = sum(value^2), .by = Residuo) %&gt;% \n  mutate(Pchisq = pchisq(SQR, df = modelo_completo$df.residual, lower.tail = F)) %&gt;% \n  flextable() %&gt;% \n  autofit() %&gt;% \n  bold(part = \"header\")\n\n\n\n\n\nResiduo\nSQR\nPchisq\n\n\n\nPearson\n1,084.9937\n0.1671558\n\n\nDeviance\n982.4531\n0.9020470\n\n\n\n\n\n\nAcurácia\n\nCódigomodelo_completo %&gt;% performance::performance_accuracy()\n\n# Accuracy of Model Predictions\n\nAccuracy (95% CI): 83.81% [80.14%, 86.01%]\nMethod: Area under Curve\n\n\nPorcentagem de predições corretas\n\nCódigomodelo_completo %&gt;% performance::performance_pcp()\n\n# Percentage of Correct Predictions from Logistic Regression Model\n\n  Full model: 69.86% [67.08% - 72.64%]\n  Null model: 51.68% [48.66% - 54.71%]\n\n# Likelihood-Ratio-Test\n\n  Chi-squared: 432.167\n  df:   4.000\n  p-value:   0.000\n\n\nCurva ROC\n\nCódigoEpi::ROC(form=dados$sobrevivente~ dados$sexo + dados$idade +  dados$classe, plot=\"ROC\",MI=F)\n\n\n\n\n\n\n\nPoder preditivo do modelo.\nSensibilidade e Especificidade\n\nCódigomodelo_completo %&gt;% \n  augment(type.predict = \"response\") %&gt;%\n  mutate(\n    Predito = factor(ifelse(.fitted &lt;= 0.63, \"Sim\", \"Não\"), \n                     levels = c(\"Sim\",\"Não\"))\n    ) %&gt;% \n  tbl_cross(row = sobrevivente, col = Predito, percent =  \"row\") %&gt;% \n  bold_labels() %&gt;% \n  as_flex_table()\n\n\n\n\n\n\n \nPredito\n \n\n\n\nSim\nNão\nTotal\n\n\n\n\nsobrevivente\n\n\n\n\n\nSim\n340 (80%)\n87 (20%)\n427 (100%)\n\n\nNão\n146 (24%)\n473 (76%)\n619 (100%)\n\n\nTotal\n486 (46%)\n560 (54%)\n1,046 (100%)\n\n\n\n\n\n\n\nSensibilidade: 76% (Verdadeiro positivo)\nEspecificidade: 80% (Verdadeiro negativo)\nPoder de previsão\n\nCódigomodelo_completo %&gt;% \n  augment(type.predict = \"response\") %&gt;% \n  mutate(Predito = factor(ifelse(.fitted &lt;= 0.63, \"Sim\", \"Não\"), levels = c(\"Sim\", \"Não\"))) %&gt;%\n  tbl_cross(row = sobrevivente, col = Predito, percent =  \"column\") %&gt;% \n  bold_labels() %&gt;%\n  as_flex_table()\n\n\n\n\n\n\n \nPredito\n \n\n\n\nSim\nNão\nTotal\n\n\n\n\nsobrevivente\n\n\n\n\n\nSim\n340 (70%)\n87 (16%)\n427 (41%)\n\n\nNão\n146 (30%)\n473 (84%)\n619 (59%)\n\n\nTotal\n486 (100%)\n560 (100%)\n1,046 (100%)\n\n\n\n\n\n\n\nPoder de previsão de não sobrevivente: 84%\nPoder de previsão sobrevivente: 70%"
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html#interpretação-dos-resultados",
    "href": "posts/proj - reg-logistica/index.html#interpretação-dos-resultados",
    "title": "Atividade Regressão Logistica",
    "section": "INTERPRETAÇÃO DOS RESULTADOS",
    "text": "INTERPRETAÇÃO DOS RESULTADOS\n\nCódigotabela_modelo\n\n\n\n\n\nCaracterísticas\nOR\nSE\n95% IC\nValor-p\n\n\n\nsexo\n\n\n\n\n\n\nFeminino\n—\n—\n—\n\n\n\nMasculino\n12.2\n0.166\n8.83, 16.9\n&lt;0.001\n\n\nidade\n1.03\n0.006\n1.02, 1.05\n&lt;0.001\n\n\nclasse\n\n\n\n\n\n\nAlta\n—\n—\n—\n\n\n\nMédia\n3.60\n0.226\n2.32, 5.63\n&lt;0.001\n\n\nBaixa\n9.87\n0.226\n6.39, 15.5\n&lt;0.001\n\n\nAIC\n992\n\n\n\n\n\nBIC\n1,017\n\n\n\n\n\nDeviance\n982\n\n\n\n\n\nAbreviações: IC = Intervalo de Confiança, OR = Razão de chances, SE = Erro padrão\n\n\n\n\n\nIndividuos do sexo Masculino possuem uma chance 12 vezes maior de pertencerem ao grupo de não sobrevivente quando comparado com os do sexo Feminino.\nIdade está pouco relacionada a pertença de um ou outro grupo, com uma leve tendencia a estar relacionada com a pertença ao grupo de não sobrevivente.\nIndividuos de classe Média ou Baixa estão mais relacionadas a pertença do grupo de não sobreiventes quando comparadas com a classe Alta. a chance é 3,6 vezes maior nos de classe Média e quase 10 vezes maior nos de classe baixa quando comparados com a Classe Alta."
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html#referências",
    "href": "posts/proj - reg-logistica/index.html#referências",
    "title": "Atividade Regressão Logistica",
    "section": "REFERÊNCIAS",
    "text": "REFERÊNCIAS\n\nCientística & Podcast Naruhodo: Estatística Psicobio I 2022 #30 https://www.youtube.com/live/yr657G1N7GQ?si=GSnCydg1S17aDx-V\nCientística & Podcast Naruhodo: Estatística Psicobio I 2022 #31 https://www.youtube.com/live/lCLEaVOvo-c?si=JG0NSbI3YoEh4W3R\nCientística & Podcast Naruhodo: Estatística Psicobio I 2022 #32 https://www.youtube.com/live/lCLEaVOvo-c?si=iMqFh39XcGo5R0kt\nR Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/.\nSjoberg DD, Whiting K, Curry M, Lavery JA, Larmarange J. Reproducible summary tables with the gtsummary package. The R Journal 2021;13:570–80. https://doi.org/10.32614/RJ-2021-053.\nKassambara A (2023). ggpubr: ‘ggplot2’ Based Publication Ready Plots. R package version 0.6.0, https://CRAN.R-project.org/package=ggpubr.\nLüdecke et al., (2021). performance: An R Package for Assessment, Comparison and Testing of Statistical Models. Journal of Open Source Software, 6(60), 3139. https://doi.org/10.21105/joss.03139\nWickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686 https://doi.org/10.21105/joss.01686.\nPedersen T (2024). patchwork: The Composer of Plots. R package version 1.2.0, https://CRAN.R-project.org/package=patchwork.\nGohel D, Skintzos P (2023). flextable: Functions for Tabular Reporting. R package version 0.9.4, https://CRAN.R-project.org/package=flextable."
  },
  {
    "objectID": "posts/proj - reg-logistica/index.html#setup",
    "href": "posts/proj - reg-logistica/index.html#setup",
    "title": "Atividade Regressão Logistica",
    "section": "SETUP",
    "text": "SETUP\n\nCódigo# Pacotes ----------------------------------\n  library(tidyverse) # manipulação dos dados e ggplot2\n  library(ggpubr) # gráficos \n  library(flextable) # tabelas\n  library(gtsummary) # tabelas\n  library(patchwork) # gráficos\n  library(broom) # \n\n# Configurações ----------------------------\n  theme_set(theme_test())\n  gtsummary::theme_gtsummary_language(\"pt\")"
  },
  {
    "objectID": "posts/proj - eda loan data/notas-de-estudo.html",
    "href": "posts/proj - eda loan data/notas-de-estudo.html",
    "title": "Modelos de Classificação ~ Notas de Aula 01",
    "section": "",
    "text": "Meu objetivo nesse projeto é estudar e pratica modelos de classificação. Desejo fazer uso da coleção de pacotes do tidymodels em todo o projeto."
  },
  {
    "objectID": "posts/proj - eda loan data/notas-de-estudo.html#introdução",
    "href": "posts/proj - eda loan data/notas-de-estudo.html#introdução",
    "title": "Modelos de Classificação ~ Notas de Aula 01",
    "section": "",
    "text": "Meu objetivo nesse projeto é estudar e pratica modelos de classificação. Desejo fazer uso da coleção de pacotes do tidymodels em todo o projeto."
  },
  {
    "objectID": "posts/proj - eda loan data/analise_exploratoria_loan_data.html",
    "href": "posts/proj - eda loan data/analise_exploratoria_loan_data.html",
    "title": "Analise Exploratoria: loan_data",
    "section": "",
    "text": "Code\n# Análise exploratória de dados: \n\n# Conjunto de dados: datasets/loan_data.csv\n## https://www.kaggle.com/datasets/saramah/loan-data/data\n\n# Pacotes e conjunto de dados ---------------------------------------------\n\nlibrary(tidyverse)\nlibrary(enoqueR)\nlibrary(gt)\n\ndados = read_csv(\"datasets/loan_data.csv\")"
  },
  {
    "objectID": "posts/proj - eda loan data/analise_exploratoria_loan_data.html#visão-geral",
    "href": "posts/proj - eda loan data/analise_exploratoria_loan_data.html#visão-geral",
    "title": "Analise Exploratoria: loan_data",
    "section": "1 Visão geral",
    "text": "1 Visão geral\n\n\nCode\nbind_rows(\n  enoqueR::overall_info(dados),\n  enoqueR::overall_tipos(dados)\n  ) %&gt;% \n  gt() %&gt;% \n  opt_interactive()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndados %&gt;% \n  head() %&gt;%\n  gt() %&gt;% \n  fmt_number(where(is.numeric)) %&gt;%\n  opt_interactive()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nvariaveis_pt &lt;- c(\n  \"politica_credito\" = \"credit.policy\",\n  \"proposito_emp\" = \"purpose\",\n  \"taxa_juros\" = \"int.rate\",\n  \"parcela_mensal\" = \"installment\",\n  \"log_renda_anual\" = \"log.annual.inc\",\n  \"indice_divida_renda\" = \"dti\",\n  \"pontuacao_fico\" = \"fico\",\n  \"dias_com_credito\" = \"days.with.cr.line\",\n  \"saldo_rotativo\" = \"revol.bal\",\n  \"taxa_utilizacao_rotativa\" = \"revol.util\",\n  \"consultas_ultimos_6_meses\" = \"inq.last.6mths\",\n  \"atrasos_ultimos_2_anos\" = \"delinq.2yrs\",\n  \"registros_publicos_negativos\" = \"pub.rec\"\n)\n\n\n\n\nCode\ndados &lt;- dados %&gt;% \n  rename(all_of(variaveis_pt)) %&gt;% \n  mutate(proposito_emp = case_when(\n    proposito_emp == \"credit_card\" ~ \"Cartão de credito\",\n    proposito_emp == \"debt_consolidation\" ~ \"Consolidação de divida\",\n    proposito_emp == \"educational\" ~ \"Educacional\",\n    proposito_emp == \"major_purchase\" ~ \"Compra grande\",\n    proposito_emp == \"small_business\" ~ \"Pequeno Negócio\",\n    proposito_emp == \"all_other\" ~ \"Outro\",\n    .default = proposito_emp\n    ),\n    politica_credito = fct(if_else(politica_credito == 1, \"Sim\", \"Não\"), levels = c(\"Não\", \"Sim\"))\n  )"
  },
  {
    "objectID": "posts/proj - eda loan data/analise_exploratoria_loan_data.html#análise-descritiva",
    "href": "posts/proj - eda loan data/analise_exploratoria_loan_data.html#análise-descritiva",
    "title": "Analise Exploratoria: loan_data",
    "section": "2 Análise descritiva",
    "text": "2 Análise descritiva\n\n\nCode\ndados %&gt;% \n  enoqueR::tbl_resumo()\n\n\n\n\n\n\n  Estatísticas Descritivas\n  \n    \n      Variável\n      N (%)\n      Média (DP)\n      Mediana (IQR)\n      Min - Max\n    \n  \n  \n    taxa_juros\n-\n0.123 (0.027)\n0.122 (0.104, 0.141)\n0.060 - 0.216\n    parcela_mensal\n-\n319 (207)\n269 (164, 433)\n16 - 940\n    log_renda_anual\n-\n10.93 (0.61)\n10.93 (10.56, 11.29)\n7.55 - 14.53\n    indice_divida_renda\n-\n13 (7)\n13 (7, 18)\n0 - 30\n    pontuacao_fico\n-\n711 (38)\n707 (682, 737)\n612 - 827\n    dias_com_credito\n-\n4,561 (2,497)\n4,140 (2,820, 5,730)\n179 - 17,640\n    saldo_rotativo\n-\n16,914 (33,756)\n8,596 (3,187, 18,250)\n0 - 1,207,359\n    taxa_utilizacao_rotativa\n-\n47 (29)\n46 (23, 71)\n0 - 119\n    consultas_ultimos_6_meses\n-\n1.58 (2.20)\n1.00 (0.00, 2.00)\n0.00 - 33.00\n    atrasos_ultimos_2_anos\n-\n0.16 (0.55)\n0.00 (0.00, 0.00)\n0.00 - 13.00\n    registros_publicos_negativos\n-\n-\n-\n-\n        0\n-\n9,019 (94%)\n9,019 (94%)\n9,019 (94%)\n        1\n-\n533 (5.6%)\n533 (5.6%)\n533 (5.6%)\n        2\n-\n19 (0.2%)\n19 (0.2%)\n19 (0.2%)\n        3\n-\n5 (&lt;0.1%)\n5 (&lt;0.1%)\n5 (&lt;0.1%)\n        4\n-\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n        5\n-\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n    not.fully.paid\n-\n1,533 (16%)\n1,533 (16%)\n1,533 (16%)\n    politica_credito\n-\n-\n-\n-\n        Não\n1,868 (20%)\n-\n-\n-\n        Sim\n7,710 (80%)\n-\n-\n-\n    proposito_emp\n-\n-\n-\n-\n        Cartão de credito\n1,262 (13%)\n-\n-\n-\n        Compra grande\n437 (4.6%)\n-\n-\n-\n        Consolidação de divida\n3,957 (41%)\n-\n-\n-\n        Educacional\n343 (3.6%)\n-\n-\n-\n        home_improvement\n629 (6.6%)\n-\n-\n-\n        Outro\n2,331 (24%)\n-\n-\n-\n        Pequeno Negócio\n619 (6.5%)\n-\n-\n-\n  \n  \n  \n\n\n\n\n\n\nCode\ndados %&gt;% \n    enoqueR::variaveis() %&gt;% \n    gt() %&gt;% \n    fmt_number() %&gt;% \n    tab_style(\n      style = \"vertical-align:middle; font-weight: bold\",\n      locations = cells_column_labels()\n    )\n\n\n\n\n\n\n  \n    \n      name\n      atrasos_ultimos_2_anos\n      consultas_ultimos_6_meses\n      dias_com_credito\n      indice_divida_renda\n      log_renda_anual\n      not.fully.paid\n      parcela_mensal\n      pontuacao_fico\n      registros_publicos_negativos\n      saldo_rotativo\n      taxa_juros\n      taxa_utilizacao_rotativa\n      politica_credito\n      proposito_emp\n    \n  \n  \n    n\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n    min\n0.00\n0.00\n178.96\n0.00\n7.55\n0.00\n15.67\n612.00\n0.00\n0.00\n0.06\n0.00\nNA\nNA\n    max\n13.00\n33.00\n17,639.96\n29.96\n14.53\n1.00\n940.14\n827.00\n5.00\n1,207,359.00\n0.22\n119.00\nNA\nNA\n    median\n0.00\n1.00\n4,139.96\n12.66\n10.93\n0.00\n268.95\n707.00\n0.00\n8,596.00\n0.12\n46.30\nNA\nNA\n    q1\n0.00\n0.00\n2,820.00\n7.21\n10.56\n0.00\n163.77\n682.00\n0.00\n3,187.00\n0.10\n22.60\nNA\nNA\n    q3\n0.00\n2.00\n5,730.00\n17.95\n11.29\n0.00\n432.76\n737.00\n0.00\n18,249.50\n0.14\n70.90\nNA\nNA\n    iqr\n0.00\n2.00\n2,910.00\n10.74\n0.73\n0.00\n268.99\n55.00\n0.00\n15,062.50\n0.04\n48.30\nNA\nNA\n    mad\n0.00\n1.48\n2,135.07\n7.98\n0.54\n0.00\n184.88\n37.06\n0.00\n9,619.11\n0.03\n35.88\nNA\nNA\n    mean\n0.16\n1.58\n4,560.77\n12.61\n10.93\n0.16\n319.09\n710.85\n0.06\n16,913.96\n0.12\n46.80\nNA\nNA\n    sd\n0.55\n2.20\n2,496.93\n6.88\n0.61\n0.37\n207.07\n37.97\n0.26\n33,756.19\n0.03\n29.01\nNA\nNA\n    se\n0.01\n0.02\n25.51\n0.07\n0.01\n0.00\n2.12\n0.39\n0.00\n344.92\n0.00\n0.30\nNA\nNA\n    ci\n0.01\n0.04\n50.01\n0.14\n0.01\n0.01\n4.15\n0.76\n0.00\n676.11\n0.00\n0.58\nNA\nNA\n    var\n0.30\n4.84\n6,234,659.42\n47.39\n0.38\n0.13\n42,878.40\n1,441.80\n0.07\n1,139,480,363.32\n0.00\n841.81\nNA\nNA\n    range\n13.00\n33.00\n17,461.00\n29.96\n6.98\n1.00\n924.47\n215.00\n5.00\n1,207,359.00\n0.16\n119.00\nNA\nNA\n    cv\n1.82\n3.07\n1,367.02\n3.76\n0.03\n0.84\n134.38\n2.03\n1.11\n67,369.21\n0.01\n17.99\nNA\nNA\n    distinct\n11.00\n28.00\n2,687.00\n2,529.00\n1,987.00\n2.00\n4,788.00\n44.00\n6.00\n7,869.00\n249.00\n1,035.00\n2.00\n7.00\n    ausente\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n    ausente_pct\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n    zeros\n8,458.00\n3,637.00\n0.00\n89.00\n0.00\n8,045.00\n0.00\n0.00\n9,019.00\n321.00\n0.00\n297.00\nNA\nNA\n    zeros_pct\n0.88\n0.38\n0.00\n0.01\n0.00\n0.84\n0.00\n0.00\n0.94\n0.03\n0.00\n0.03\nNA\nNA\n    q.5\n0.00\n0.00\n1,320.04\n1.27\n9.92\n0.00\n65.56\n657.00\n0.00\n127.70\n0.08\n1.10\nNA\nNA\n    q.95\n1.00\n5.00\n9,329.96\n23.65\n11.92\n1.00\n756.27\n782.00\n1.00\n57,654.30\n0.17\n94.00\nNA\nNA\n    curtose\n74.40\n29.27\n4.94\n2.10\n4.61\n4.44\n3.14\n2.58\n41.76\n262.52\n2.78\n1.88\nNA\nNA\n    assimetria\n6.06\n3.58\n1.16\n0.02\n0.03\n1.85\n0.91\n0.47\n5.13\n11.16\n0.16\n0.06\nNA\nNA\n  \n  \n  \n\n\n\n\n\n\nCode\ndados %&gt;% \n    enoqueR::eda_tabela_dataset_resumo_num()\n\n\n\n\n  \n\n\n\n\n\nCode\ndados %&gt;% \n  enoqueR::eda_visual_dataset_hist()\n\n\n\n\n\n\n\nCode\ndados %&gt;% \n  enoqueR::eda_visual_dataset_resposta(resposta = \"politica_credito\")"
  },
  {
    "objectID": "posts/proj - eda loan data/analise_exploratoria_loan_data.html#próximos-passos",
    "href": "posts/proj - eda loan data/analise_exploratoria_loan_data.html#próximos-passos",
    "title": "Analise Exploratoria: loan_data",
    "section": "3 Próximos passos",
    "text": "3 Próximos passos\n\nAnálisar associação/correlação entre a covariaveis"
  },
  {
    "objectID": "posts/proj - reg_logistica tidymodels/classificacao - reg_log.html",
    "href": "posts/proj - reg_logistica tidymodels/classificacao - reg_log.html",
    "title": "Classificação por regressão logistica",
    "section": "",
    "text": "\\[g: \\mathbb{R}^p \\to \\{-1, 1\\}.\\] \\[\\log \\left(\\frac{P(Y_i = 1 \\mid X = x)}{P(Y_i = 0 \\mid X = x)}\\right) = \\alpha + \\beta x_i, \\quad i = 1, \\dots, n.\\]\n\\[\\log\\left[\\frac{\\theta(x_i; \\alpha, \\beta)}{1 - \\theta(x_i; \\alpha, \\beta)}\\right] = \\alpha + x_i \\beta,\\]\n\\(\\theta(x_i; \\alpha, \\beta)\\): probabilidade de \\(Y = 1\\) dado que \\(X = x_i\\)\n\\(\\alpha\\): logaritmo da chance \\(Y=1\\) dado \\(X = x_i\\)\n\\(\\beta\\): a variação no logaritmo da chance de \\(Y =1\\) dado que \\(X = x_i\\).\nEsse é o logaritmo da chance de resposta positiva. É uma função da média para dados dicotomicos no qual 0 é atribuido a resposta negativa e 1 a positiva.\ndas categorias 0 ou 1 passamos para um intervalo granulado quando modelos a chance de 1 em relação a 0 e atráves do log dessa chance obtemos um intervalo entre 0 e 1.\nReprodução do exemplo de modelagem de regressão logistica do Livro Estatística e Ciência de Dados (Morettin e Singer) utilizando o tidymodels.\n# pacotes:\n  library(tidyverse)\n  library(tidymodels)\n  library(gtsummary)\n  library(patchwork)\n# dados:\n  dados_disco = readxl::read_xls(\"disco.xls\",sheet = 'dados')\ndados_disco %&gt;% \n  ggplot(aes(x = distanciaA, y = deslocamento)) + \n  geom_point()  + \n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = FALSE, color = \"darkorange\") + \n  theme_test()\n(dados_disco %&gt;% \n  count(deslocamento) %&gt;% \n  ggpubr::ggbarplot(x = \"deslocamento\", y = \"n\", label = T)) + \n\n(dados_disco %&gt;% \n  ggpubr::ggdensity(x = \"distanciaA\"))\nHá desbalanceamento nas proporções da variáveis resposta. Devemos levar isso em consideração ao escolher qual critério de reamostragem utilizar para separar os dados em treino e teste. Nessas situações podemos fazer uso da amostragem estratificada que realiza a coleta/separação das observações estratificando-as por um alguma variável e retornando amostras com proporções balanceadas para cada grupo da variável de estratificação.\ndados_disco &lt;-  \n  dados_disco %&gt;% \n  mutate(\n    deslocamento = fct(if_else(deslocamento == 1, \"deslocado\", \"não deslocado\"), levels = c(\"não deslocado\", \"deslocado\")),\n    )\nset.seed(31)\n\ndados_disco_split &lt;- \n  dados_disco %&gt;% \n  initial_split(prop = 0.8, strata = deslocamento)\n\ndados_disco_treino = training(dados_disco_split)\ndados_disco_teste = testing(dados_disco_split)\nA seguir faço a especificação modelo que irei utilizar. Será utilizado o método de regressão linear generalizado no será utilizado a função de ligação logit para transformar a variável resposta com distribuição binomial para o espaço de probabilidade {0,1}.\nIrei utilizar uma abordagem cuja estrutura matemática é a função de ligação logit, farei isso atráves da egine glm com o argumento family = binomial (link logit)\nlog_reg &lt;- \n  logistic_reg() %&gt;% \n  set_engine(\"glm\", family = \"binomial\") %&gt;% \n  set_mode(\"classification\")\n\nlog_reg %&gt;% translate()\n\nLogistic Regression Model Specification (classification)\n\nEngine-Specific Arguments:\n  family = binomial\n\nComputational engine: glm \n\nModel fit template:\nstats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n    family = \"binomial\")\nAgora especifico a receita que irei utilizar. A receita corresponde ao descrição de como as variáveis explicativas se conectam com a variável resposta. Estamos dizendo como o modelo que iremos utilizar irá organizar e interpretar cada variável. Aqui também especificamos os passos de engenharia de recursos. a partir das funções step_... podemos aplicar diversas passos para modificar as variáveis que aparecem na receita. Podemos criar novas variáveis, centralizar, escalar e etc.\nreceita_1 &lt;-  \n  recipe(deslocamento ~ distanciaA, data = dados_disco) %&gt;% \n  step_mutate(distanciaA = distanciaA - min(distanciaA))\nIniciamos o workflow() para a execução do ajuste (fit) do modelo. Com o workflow iniciado adicionamos (add_...) a ele o modelo que será utilizado, bem como a receita e então realizamos o ajuste.\nmodelo_1 &lt;- \n  workflow()  %&gt;%  \n  add_model(log_reg) %&gt;% \n  add_recipe(receita_1) %&gt;% \n  fit(data = dados_disco)\n\nmodelo_1\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_mutate()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = ~\"binomial\", data = data)\n\nCoefficients:\n(Intercept)   distanciaA  \n     -5.859        3.164  \n\nDegrees of Freedom: 103 Total (i.e. Null);  102 Residual\nNull Deviance:      123.1 \nResidual Deviance: 71.6     AIC: 75.6\nmodelo_1 %&gt;% \n  extract_fit_engine()\n\n\nCall:  stats::glm(formula = ..y ~ ., family = ~\"binomial\", data = data)\n\nCoefficients:\n(Intercept)   distanciaA  \n     -5.859        3.164  \n\nDegrees of Freedom: 103 Total (i.e. Null);  102 Residual\nNull Deviance:      123.1 \nResidual Deviance: 71.6     AIC: 75.6\ndados_disco %&gt;% \n  ggplot(aes(x = distanciaA - min(distanciaA), y = deslocamento)) + \n  geom_point()"
  },
  {
    "objectID": "posts/proj - reg_logistica tidymodels/classificacao - reg_log.html#referências",
    "href": "posts/proj - reg_logistica tidymodels/classificacao - reg_log.html#referências",
    "title": "Classificação por regressão logistica",
    "section": "Referências",
    "text": "Referências\n\nMORETTIN, Pedro Alberto e SINGER, Júlio da Motta. Estatística e ciência de dados. . Rio de Janeiro: LTC\nhttps://www.tmwr.org."
  },
  {
    "objectID": "posts/proj - reg_logistica tidymodels/index.html",
    "href": "posts/proj - reg_logistica tidymodels/index.html",
    "title": "Classificação por regressão logistica",
    "section": "",
    "text": "\\[g: \\mathbb{R}^p \\to \\{-1, 1\\}.\\] \\[\\log \\left(\\frac{P(Y_i = 1 \\mid X = x)}{P(Y_i = 0 \\mid X = x)}\\right) = \\alpha + \\beta x_i, \\quad i = 1, \\dots, n.\\]\n\\[\\log\\left[\\frac{\\theta(x_i; \\alpha, \\beta)}{1 - \\theta(x_i; \\alpha, \\beta)}\\right] = \\alpha + x_i \\beta,\\]\n\\(\\theta(x_i; \\alpha, \\beta)\\): probabilidade de \\(Y = 1\\) dado que \\(X = x_i\\)\n\\(\\alpha\\): logaritmo da chance \\(Y=1\\) dado \\(X = x_i\\)\n\\(\\beta\\): a variação no logaritmo da chance de \\(Y =1\\) dado que \\(X = x_i\\).\nEsse é o logaritmo da chance de resposta positiva. É uma função da média para dados dicotomicos no qual 0 é atribuido a resposta negativa e 1 a positiva.\ndas categorias 0 ou 1 passamos para um intervalo granulado quando modelos a chance de 1 em relação a 0 e atráves do log dessa chance obtemos um intervalo entre 0 e 1.\nReprodução do exemplo de modelagem de regressão logistica do Livro Estatística e Ciência de Dados (Morettin e Singer) utilizando o tidymodels.\n# pacotes:\n  library(tidyverse)\n  library(tidymodels)\n  library(gtsummary)\n  library(patchwork)\n# dados:\n  dados_disco = readxl::read_xls(\"disco.xls\",sheet = 'dados')\ndados_disco %&gt;% \n  ggplot(aes(x = distanciaA, y = deslocamento)) + \n  geom_point()  + \n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = FALSE, color = \"darkorange\") + \n  theme_test()\n(dados_disco %&gt;% \n  count(deslocamento) %&gt;% \n  ggpubr::ggbarplot(x = \"deslocamento\", y = \"n\", label = T)) + \n\n(dados_disco %&gt;% \n  ggpubr::ggdensity(x = \"distanciaA\"))\nHá desbalanceamento nas proporções da variáveis resposta. Devemos levar isso em consideração ao escolher qual critério de reamostragem utilizar para separar os dados em treino e teste. Nessas situações podemos fazer uso da amostragem estratificada que realiza a coleta/separação das observações estratificando-as por um alguma variável e retornando amostras com proporções balanceadas para cada grupo da variável de estratificação.\ndados_disco &lt;-  \n  dados_disco %&gt;% \n  mutate(\n    deslocamento = fct(if_else(deslocamento == 1, \"deslocado\", \"não deslocado\"), levels = c(\"não deslocado\", \"deslocado\")),\n    )\nset.seed(31)\n\ndados_disco_split &lt;- \n  dados_disco %&gt;% \n  initial_split(prop = 0.8, strata = deslocamento)\n\ndados_disco_treino = training(dados_disco_split)\ndados_disco_teste = testing(dados_disco_split)\nA seguir faço a especificação modelo que irei utilizar. Será utilizado o método de regressão linear generalizado no será utilizado a função de ligação logit para transformar a variável resposta com distribuição binomial para o espaço de probabilidade {0,1}.\nIrei utilizar uma abordagem cuja estrutura matemática é a função de ligação logit, farei isso atráves da egine glm com o argumento family = binomial (link logit)\nlog_reg &lt;- \n  logistic_reg() %&gt;% \n  set_engine(\"glm\", family = \"binomial\") %&gt;% \n  set_mode(\"classification\")\n\nlog_reg %&gt;% translate()\n\nLogistic Regression Model Specification (classification)\n\nEngine-Specific Arguments:\n  family = binomial\n\nComputational engine: glm \n\nModel fit template:\nstats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n    family = \"binomial\")\nAgora especifico a receita que irei utilizar. A receita corresponde ao descrição de como as variáveis explicativas se conectam com a variável resposta. Estamos dizendo como o modelo que iremos utilizar irá organizar e interpretar cada variável. Aqui também especificamos os passos de engenharia de recursos. a partir das funções step_... podemos aplicar diversas passos para modificar as variáveis que aparecem na receita. Podemos criar novas variáveis, centralizar, escalar e etc.\nreceita_1 &lt;-  \n  recipe(deslocamento ~ distanciaA, data = dados_disco) %&gt;% \n  step_mutate(distanciaA = distanciaA - min(distanciaA))\nIniciamos o workflow() para a execução do ajuste (fit) do modelo. Com o workflow iniciado adicionamos (add_...) a ele o modelo que será utilizado, bem como a receita e então realizamos o ajuste.\nmodelo_1 &lt;- \n  workflow()  %&gt;%  \n  add_model(log_reg) %&gt;% \n  add_recipe(receita_1) %&gt;% \n  fit(data = dados_disco)\n\nmodelo_1\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_mutate()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = ~\"binomial\", data = data)\n\nCoefficients:\n(Intercept)   distanciaA  \n     -5.859        3.164  \n\nDegrees of Freedom: 103 Total (i.e. Null);  102 Residual\nNull Deviance:      123.1 \nResidual Deviance: 71.6     AIC: 75.6\nmodelo_1 %&gt;% \n  extract_fit_engine()\n\n\nCall:  stats::glm(formula = ..y ~ ., family = ~\"binomial\", data = data)\n\nCoefficients:\n(Intercept)   distanciaA  \n     -5.859        3.164  \n\nDegrees of Freedom: 103 Total (i.e. Null);  102 Residual\nNull Deviance:      123.1 \nResidual Deviance: 71.6     AIC: 75.6\ndados_disco %&gt;% \n  ggplot(aes(x = distanciaA - min(distanciaA), y = deslocamento)) + \n  geom_point()"
  },
  {
    "objectID": "posts/proj - reg_logistica tidymodels/index.html#referências",
    "href": "posts/proj - reg_logistica tidymodels/index.html#referências",
    "title": "Classificação por regressão logistica",
    "section": "Referências",
    "text": "Referências\n\nMORETTIN, Pedro Alberto e SINGER, Júlio da Motta. Estatística e ciência de dados. . Rio de Janeiro: LTC\nhttps://www.tmwr.org."
  },
  {
    "objectID": "posts/proj - infer/index.html",
    "href": "posts/proj - infer/index.html",
    "title": "Inferência Estatística Organizada: no R",
    "section": "",
    "text": "Esse texto tem como objetivo apresentar o pacote infer que tem como objetivo principal a realização de procedimentos de inferência estatística de forma organizada, seguindo a filosofia tidy.\nlibrary(tidyverse)\nlibrary(infer)\nlibrary(gt)\nlibrary(flextable)\ntheme_set(theme_test())"
  },
  {
    "objectID": "posts/proj - infer/index.html#conjunto-de-dados-utilizado",
    "href": "posts/proj - infer/index.html#conjunto-de-dados-utilizado",
    "title": "Inferência Estatística Organizada: no R",
    "section": "Conjunto de dados utilizado",
    "text": "Conjunto de dados utilizado\nas vinhetas do pacote infer utilizam o conjunto de dados gss que corresponde a Subconjunto de dados da Pesquisa Social Geral (GSS)., traduzido literalmente do help(gss): Subset of data from the General Social Survey (GSS).\n\nThe General Social Survey is a high-quality survey which gathers data on American society and opinions, conducted since 1972. This data set is a sample of 500 entries from the GSS, spanning years 1973-2018, including demographic markers and some economic variables. Note that this data is included for demonstration only, and should not be assumed to provide accurate estimates relating to the GSS. However, due to the high quality of the GSS, the unweighted data will approximate the weighted data in some analyses.\nO General Social Survey é um inquérito de alta qualidade que reúne dados sobre a sociedade e as opiniões americanas, realizado desde 1972. Este conjunto de dados é uma amostra de 500 entradas do GSS, abrangendo os anos 1973-2018, incluindo marcadores demográficos e algumas variáveis económicas. Note-se que estes dados são incluídos apenas para demonstração e não devem ser considerados como fornecendo estimativas precisas relativas ao GSS. Contudo, devido à elevada qualidade do GSS, os dados não ponderados aproximar-se-ão dos dados ponderados em algumas análises.\n\n\nnomes_traduzidos = c(\n  'ano', 'idade', 'sexo', 'faculdade','id_partido','dom_pop',\n  'horas', 'renda', 'classe', 'fam_renda_opn', 'peso'\n  )\n\n\nglimpse(gss)\n\nRows: 500\nColumns: 11\n$ year    &lt;dbl&gt; 2014, 1994, 1998, 1996, 1994, 1996, 1990, 2016, 2000, 1998, 20…\n$ age     &lt;dbl&gt; 36, 34, 24, 42, 31, 32, 48, 36, 30, 33, 21, 30, 38, 49, 25, 56…\n$ sex     &lt;fct&gt; male, female, male, male, male, female, female, female, female…\n$ college &lt;fct&gt; degree, no degree, degree, no degree, degree, no degree, no de…\n$ partyid &lt;fct&gt; ind, rep, ind, ind, rep, rep, dem, ind, rep, dem, dem, ind, de…\n$ hompop  &lt;dbl&gt; 3, 4, 1, 4, 2, 4, 2, 1, 5, 2, 4, 3, 4, 4, 2, 2, 3, 2, 1, 2, 5,…\n$ hours   &lt;dbl&gt; 50, 31, 40, 40, 40, 53, 32, 20, 40, 40, 23, 52, 38, 72, 48, 40…\n$ income  &lt;ord&gt; $25000 or more, $20000 - 24999, $25000 or more, $25000 or more…\n$ class   &lt;fct&gt; middle class, working class, working class, working class, mid…\n$ finrela &lt;fct&gt; below average, below average, below average, above average, ab…\n$ weight  &lt;dbl&gt; 0.8960034, 1.0825000, 0.5501000, 1.0864000, 1.0825000, 1.08640…\n\n\n\ngss %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \n  ggplot(aes(x = name, y = value, color = name)) + \n  #geom_jitter(alpha = 0.6) + \n  geom_violin(aes(), linewidth =0.8, fill ='#ffffffff') + \n  geom_boxplot(notch = TRUE, outlier.shape= 15, outlier.color = 'black',\n               alpha = 0.5, linewidth =0.8) + \n  facet_wrap(~name, scales = 'free', nrow =1) + \n  theme_minimal() + \n  theme(legend.position ='none')\n\n\n\n\n\nspecify()\ncalculate()\nobserve()\nhyhotesize()\ngenerate()"
  },
  {
    "objectID": "posts/proj - infer/index.html#uma-variável-numérica-média",
    "href": "posts/proj - infer/index.html#uma-variável-numérica-média",
    "title": "Inferência Estatística Organizada: no R",
    "section": "Uma variável numérica (média)",
    "text": "Uma variável numérica (média)\n\nx_barra &lt;- \n  gss %&gt;% \n  observe(response = hours, stat = 'mean')\n\n\ndist_nula &lt;-\n  gss %&gt;%\n  specify(response = hours) %&gt;%\n  hypothesize(null = \"point\", mu = 40) %&gt;%\n  generate(reps = 1000) %&gt;%\n  calculate(stat = \"mean\")\n\n\nvisualize(dist_nula) +\n  shade_p_value(obs_stat = x_barra, direction = 'two-sided')\n\n\n\n\n\ndist_nula %&gt;% \n  get_p_value(obs_stat = x_barra, direction = 'two-sided')\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1   0.038"
  },
  {
    "objectID": "posts/proj - infer/index.html#uma-variável-numérica-standardized-mean-t",
    "href": "posts/proj - infer/index.html#uma-variável-numérica-standardized-mean-t",
    "title": "Inferência Estatística Organizada: no R",
    "section": "Uma variável numérica (standardized mean t)",
    "text": "Uma variável numérica (standardized mean t)\n\n t_barra = gss %&gt;% \n   specify(response = hours) %&gt;% \n   hypothesise(null = 'point', mu = 40) %&gt;% \n   calculate(stat = 't')\n\n t_barra &lt;- gss %&gt;%\n   observe(response = hours, null = \"point\", mu = 40, stat = \"t\")\n t_barra\n\nResponse: hours (numeric)\nNull Hypothesis: point\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  2.09\n\n\nGerar a distribuição nula:\n\n# gerar a distribuição nula\ngss %&gt;% \n  specify(response = hours) %&gt;% \n  hypothesise(null = 'point', mu = 40) %&gt;% \n  generate(reps = 1000) %&gt;% \n  calculate(stat = 't') %&gt;% \n  visualize(method = 'both') +\n  shade_p_value(obs_stat = t_barra, direction = 'two-sided')\n\n\n\n\nAlternativamente, encontrar a distribuição nula usando metodos teóricos com o verbo assume():\n\ngss %&gt;% \n  specify(response = hours) %&gt;% \n  assume('t') %&gt;% \n  visualize() + \n  shade_p_value(obs_stat = t_barra, direction = 'two-sided')\n\n\n\n\n\ngss %&gt;% \n  specify(response = hours) %&gt;% \n  hypothesise(null = 'point', mu = 40) %&gt;% \n  generate(reps = 1000) %&gt;% \n  calculate(stat = 't') %&gt;% \n  get_p_value(obs_stat = t_barra, direction = \"two-sided\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1    0.04\n\n\n\ngss %&gt;% t_test(response = hours, mu = 40)\n\n# A tibble: 1 × 7\n  statistic  t_df p_value alternative estimate lower_ci upper_ci\n      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1      2.09   499  0.0376 two.sided       41.4     40.1     42.7"
  },
  {
    "objectID": "index.html#habilidades",
    "href": "index.html#habilidades",
    "title": "Sobre mim",
    "section": "",
    "text": "Estatística | Analise de Dados\nR, Excel, Power BI, Power Query.\nExcel\nPacote Office\nInglês: Intermediário"
  },
  {
    "objectID": "index.html#experiência-profissional",
    "href": "index.html#experiência-profissional",
    "title": "Sobre mim",
    "section": "Experiência Profissional",
    "text": "Experiência Profissional\n\nAssistente administrativo | 2024 - Atualmente\nConsultoria estatística acadêmica e analise de dados| 2025 - Atualmente"
  },
  {
    "objectID": "posts/proj - eda-loan-data/index.html",
    "href": "posts/proj - eda-loan-data/index.html",
    "title": "Analise Exploratoria: loan_data",
    "section": "",
    "text": "Code\n# Análise exploratória de dados: \n\n# Conjunto de dados: datasets/loan_data.csv\n## https://www.kaggle.com/datasets/saramah/loan-data/data\n\n# Pacotes e conjunto de dados ---------------------------------------------\n\nlibrary(tidyverse)\nlibrary(enoqueR)\nlibrary(gt)\n\ndados = read_csv(\"datasets/loan_data.csv\")"
  },
  {
    "objectID": "posts/proj - eda-loan-data/index.html#visão-geral",
    "href": "posts/proj - eda-loan-data/index.html#visão-geral",
    "title": "Analise Exploratoria: loan_data",
    "section": "1 Visão geral",
    "text": "1 Visão geral\n\n\nCode\nbind_rows(\n  enoqueR::overall_info(dados),\n  enoqueR::overall_tipos(dados)\n  ) %&gt;% \n  gt() %&gt;% \n  opt_interactive()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndados %&gt;% \n  head() %&gt;%\n  gt() %&gt;% \n  fmt_number(where(is.numeric)) %&gt;%\n  opt_interactive()\n\n\n\n\n\n\n\n\n\n\n\nCode\nvariaveis_pt &lt;- c(\n  \"politica_credito\" = \"credit.policy\",\n  \"proposito_emp\" = \"purpose\",\n  \"taxa_juros\" = \"int.rate\",\n  \"parcela_mensal\" = \"installment\",\n  \"log_renda_anual\" = \"log.annual.inc\",\n  \"indice_divida_renda\" = \"dti\",\n  \"pontuacao_fico\" = \"fico\",\n  \"dias_com_credito\" = \"days.with.cr.line\",\n  \"saldo_rotativo\" = \"revol.bal\",\n  \"taxa_utilizacao_rotativa\" = \"revol.util\",\n  \"consultas_ultimos_6_meses\" = \"inq.last.6mths\",\n  \"atrasos_ultimos_2_anos\" = \"delinq.2yrs\",\n  \"registros_publicos_negativos\" = \"pub.rec\"\n)\n\n\n\n\nCode\ndados &lt;- dados %&gt;% \n  rename(all_of(variaveis_pt)) %&gt;% \n  mutate(proposito_emp = case_when(\n    proposito_emp == \"credit_card\" ~ \"Cartão de credito\",\n    proposito_emp == \"debt_consolidation\" ~ \"Consolidação de divida\",\n    proposito_emp == \"educational\" ~ \"Educacional\",\n    proposito_emp == \"major_purchase\" ~ \"Compra grande\",\n    proposito_emp == \"small_business\" ~ \"Pequeno Negócio\",\n    proposito_emp == \"all_other\" ~ \"Outro\",\n    .default = proposito_emp\n    ),\n    politica_credito = fct(if_else(politica_credito == 1, \"Sim\", \"Não\"), levels = c(\"Não\", \"Sim\"))\n  )"
  },
  {
    "objectID": "posts/proj - eda-loan-data/index.html#análise-descritiva",
    "href": "posts/proj - eda-loan-data/index.html#análise-descritiva",
    "title": "Analise Exploratoria: loan_data",
    "section": "2 Análise descritiva",
    "text": "2 Análise descritiva\n\n\nCode\ndados %&gt;% \n  enoqueR::tbl_resumo()\n\n\n\n\n\n\nEstatísticas Descritivas\n\n\nVariável\nN (%)\nMédia (DP)\nMediana (IQR)\nMin - Max\n\n\n\n\ntaxa_juros\n-\n0.1 (0.0)\n0.1 (0.1, 0.1)\n0.1 - 0.2\n\n\nparcela_mensal\n-\n319.1 (207.1)\n269.0 (163.8, 432.9)\n15.7 - 940.1\n\n\nlog_renda_anual\n-\n10.9 (0.6)\n10.9 (10.6, 11.3)\n7.5 - 14.5\n\n\nindice_divida_renda\n-\n12.6 (6.9)\n12.7 (7.2, 18.0)\n0.0 - 30.0\n\n\npontuacao_fico\n-\n710.8 (38.0)\n707.0 (682.0, 737.0)\n612.0 - 827.0\n\n\ndias_com_credito\n-\n4,560.8 (2,496.9)\n4,140.0 (2,820.0, 5,730.0)\n179.0 - 17,640.0\n\n\nsaldo_rotativo\n-\n16,914.0 (33,756.2)\n8,596.0 (3,187.0, 18,252.0)\n0.0 - 1,207,359.0\n\n\ntaxa_utilizacao_rotativa\n-\n46.8 (29.0)\n46.3 (22.6, 70.9)\n0.0 - 119.0\n\n\nconsultas_ultimos_6_meses\n-\n1.6 (2.2)\n1.0 (0.0, 2.0)\n0.0 - 33.0\n\n\natrasos_ultimos_2_anos\n-\n0.2 (0.5)\n0.0 (0.0, 0.0)\n0.0 - 13.0\n\n\nregistros_publicos_negativos\n-\n-\n-\n-\n\n\n    0\n-\n9,019.0 (94.2%)\n9,019.0 (94.2%)\n9,019.0 (94.2%)\n\n\n    1\n-\n533.0 (5.6%)\n533.0 (5.6%)\n533.0 (5.6%)\n\n\n    2\n-\n19.0 (0.2%)\n19.0 (0.2%)\n19.0 (0.2%)\n\n\n    3\n-\n5.0 (0.1%)\n5.0 (0.1%)\n5.0 (0.1%)\n\n\n    4\n-\n1.0 (0.0%)\n1.0 (0.0%)\n1.0 (0.0%)\n\n\n    5\n-\n1.0 (0.0%)\n1.0 (0.0%)\n1.0 (0.0%)\n\n\nnot.fully.paid\n-\n1,533.0 (16.0%)\n1,533.0 (16.0%)\n1,533.0 (16.0%)\n\n\npolitica_credito\n-\n-\n-\n-\n\n\n    Não\n1,868.0 (19.5%)\n-\n-\n-\n\n\n    Sim\n7,710.0 (80.5%)\n-\n-\n-\n\n\nproposito_emp\n-\n-\n-\n-\n\n\n    Cartão de credito\n1,262.0 (13.2%)\n-\n-\n-\n\n\n    Compra grande\n437.0 (4.6%)\n-\n-\n-\n\n\n    Consolidação de divida\n3,957.0 (41.3%)\n-\n-\n-\n\n\n    Educacional\n343.0 (3.6%)\n-\n-\n-\n\n\n    home_improvement\n629.0 (6.6%)\n-\n-\n-\n\n\n    Outro\n2,331.0 (24.3%)\n-\n-\n-\n\n\n    Pequeno Negócio\n619.0 (6.5%)\n-\n-\n-\n\n\n\n\n\n\n\n\n\nCode\ndados %&gt;% \n    enoqueR::variaveis() %&gt;% \n    gt() %&gt;% \n    fmt_number() %&gt;% \n    tab_style(\n      style = \"vertical-align:middle; font-weight: bold\",\n      locations = cells_column_labels()\n    )\n\n\n\n\n\n\n\n\nname\natrasos_ultimos_2_anos\nconsultas_ultimos_6_meses\ndias_com_credito\nindice_divida_renda\nlog_renda_anual\nnot.fully.paid\nparcela_mensal\npontuacao_fico\nregistros_publicos_negativos\nsaldo_rotativo\ntaxa_juros\ntaxa_utilizacao_rotativa\npolitica_credito\nproposito_emp\n\n\n\n\nn\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n9,578.00\n\n\nmin\n0.00\n0.00\n178.96\n0.00\n7.55\n0.00\n15.67\n612.00\n0.00\n0.00\n0.06\n0.00\nNA\nNA\n\n\nmax\n13.00\n33.00\n17,639.96\n29.96\n14.53\n1.00\n940.14\n827.00\n5.00\n1,207,359.00\n0.22\n119.00\nNA\nNA\n\n\nmedian\n0.00\n1.00\n4,139.96\n12.66\n10.93\n0.00\n268.95\n707.00\n0.00\n8,596.00\n0.12\n46.30\nNA\nNA\n\n\nq1\n0.00\n0.00\n2,820.00\n7.21\n10.56\n0.00\n163.77\n682.00\n0.00\n3,187.00\n0.10\n22.60\nNA\nNA\n\n\nq3\n0.00\n2.00\n5,730.00\n17.95\n11.29\n0.00\n432.76\n737.00\n0.00\n18,249.50\n0.14\n70.90\nNA\nNA\n\n\niqr\n0.00\n2.00\n2,910.00\n10.74\n0.73\n0.00\n268.99\n55.00\n0.00\n15,062.50\n0.04\n48.30\nNA\nNA\n\n\nmad\n0.00\n1.48\n2,135.07\n7.98\n0.54\n0.00\n184.88\n37.06\n0.00\n9,619.11\n0.03\n35.88\nNA\nNA\n\n\nmean\n0.16\n1.58\n4,560.77\n12.61\n10.93\n0.16\n319.09\n710.85\n0.06\n16,913.96\n0.12\n46.80\nNA\nNA\n\n\nsd\n0.55\n2.20\n2,496.93\n6.88\n0.61\n0.37\n207.07\n37.97\n0.26\n33,756.19\n0.03\n29.01\nNA\nNA\n\n\nse\n0.01\n0.02\n25.51\n0.07\n0.01\n0.00\n2.12\n0.39\n0.00\n344.92\n0.00\n0.30\nNA\nNA\n\n\nci\n0.01\n0.04\n50.01\n0.14\n0.01\n0.01\n4.15\n0.76\n0.00\n676.11\n0.00\n0.58\nNA\nNA\n\n\nvar\n0.30\n4.84\n6,234,659.42\n47.39\n0.38\n0.13\n42,878.40\n1,441.80\n0.07\n1,139,480,363.32\n0.00\n841.81\nNA\nNA\n\n\nrange\n13.00\n33.00\n17,461.00\n29.96\n6.98\n1.00\n924.47\n215.00\n5.00\n1,207,359.00\n0.16\n119.00\nNA\nNA\n\n\ncv\n1.82\n3.07\n1,367.02\n3.76\n0.03\n0.84\n134.38\n2.03\n1.11\n67,369.21\n0.01\n17.99\nNA\nNA\n\n\ndistinct\n11.00\n28.00\n2,687.00\n2,529.00\n1,987.00\n2.00\n4,788.00\n44.00\n6.00\n7,869.00\n249.00\n1,035.00\n2.00\n7.00\n\n\nausente\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\nausente_pct\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\nzeros\n8,458.00\n3,637.00\n0.00\n89.00\n0.00\n8,045.00\n0.00\n0.00\n9,019.00\n321.00\n0.00\n297.00\nNA\nNA\n\n\nzeros_pct\n0.88\n0.38\n0.00\n0.01\n0.00\n0.84\n0.00\n0.00\n0.94\n0.03\n0.00\n0.03\nNA\nNA\n\n\nq.5\n0.00\n0.00\n1,320.04\n1.27\n9.92\n0.00\n65.56\n657.00\n0.00\n127.70\n0.08\n1.10\nNA\nNA\n\n\nq.95\n1.00\n5.00\n9,329.96\n23.65\n11.92\n1.00\n756.27\n782.00\n1.00\n57,654.30\n0.17\n94.00\nNA\nNA\n\n\ncurtose\n74.40\n29.27\n4.94\n2.10\n4.61\n4.44\n3.14\n2.58\n41.76\n262.52\n2.78\n1.88\nNA\nNA\n\n\nassimetria\n6.06\n3.58\n1.16\n0.02\n0.03\n1.85\n0.91\n0.47\n5.13\n11.16\n0.16\n0.06\nNA\nNA\n\n\n\n\n\n\n\n\n\nCode\ndados %&gt;% \n    enoqueR::eda_tabela_dataset_resumo_num()\n\n\n\n  \n\n\n\n\n\nCode\ndados %&gt;% \n  enoqueR::eda_visual_dataset_hist()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndados %&gt;% \n  enoqueR::eda_visual_dataset_resposta(resposta = \"politica_credito\")"
  },
  {
    "objectID": "posts/proj - eda-loan-data/index.html#próximos-passos",
    "href": "posts/proj - eda-loan-data/index.html#próximos-passos",
    "title": "Analise Exploratoria: loan_data",
    "section": "3 Próximos passos",
    "text": "3 Próximos passos\n\nAnálisar associação/correlação entre a covariaveis"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog sobre Estatística",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTeste Qui-quadrado\n\n\n\n\n\n\n\n\nEnoque\n\n\n\n\n\n\n\n\n\n\n\n\nTeste-t: Comparando 2 grupos independentes\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog_posts/Teste-t comparando 2 grupos indenpendentes/comparar-2-grupos-independentes.html",
    "href": "blog_posts/Teste-t comparando 2 grupos indenpendentes/comparar-2-grupos-independentes.html",
    "title": "Teste-t: Comparando 2 grupos independentes",
    "section": "",
    "text": "O teste-t é um método da estatística utilizado para responder o seguinte tipo de pergunta:\n\n“Existe efeito de uma variável categóricas com 2 grupos ou medidas sobre uma variável continua?”\n\nQuando a variável categórica corresponde a 2 grupos (independentes) chamamos de teste-t independente e quando ela corresponde a duas medidas de um mesmo grupo, chamamos de teste-t pareado.\nPor trás dos panos o teste-t verifica se a média dos grupos ou medidas são estatísticamente diferentes. Por conta disso é necessário que a distribuição da variável continua seja simétrica pois a média é um estatística que é muito afetada por valores muito grandes ou muito pequenos. Além disso também é necessário que a variancia entre os grupos sejam aproximadamente iguais. Esses dois requisitos podem ser verificados a partir de outros métodos como teste de shapiro-wilk e qqplot para a simetria e o teste de levene para a variância. Quando esses requisitos não são atendidos é necessário adicionar correções ao teste-t (correção de Welch quando as variâncias não são iguais) ou aplicar outros métodos de comparação de grupo como, por exemplo, o teste U de Mann-Whitney, quando a distribuição é muito assimétrica.\nPara exemplificar o uso desse método considere um estudo no o objetivo era avaliar o efeito de duas formas de suplementação de vitamina C no crescimento de dentes de porquinhos-da-india. Os pesquisadores realizaram um ensaio clinico com 2 grupos de cobais onde um grupo recebeu suco de laranja e outro ácido ascórbico.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeste de shapiro-wilk para avaliar a normalidade (simetria) das observações\n\n\nTipo de suplementação\nvariable\nstatistic\np\n\n\n\n\nSuco de laranja\nlen\n0.8927435\n0.182\n\n\nÁcido ascorbico\nlen\n0.8899969\n0.170\n\n\n\n\n\n\n\n\n\n\n\nTeste de levene para avaliar a homogeneidade (variância apróximadas) das observações\n\n\ndf1\ndf2\nstatistic\np\n\n\n\n\n1\n18\n3.380434\n0.083\n\n\n\n\n\n\n\n\nOs Resultados\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariável\n\nSexo\n\nDiferença2\nt2\n95% IC2\nValor-p2\n\n\nÁcido ascorbico\nN = 101\nSuco de laranja\nN = 101\n\n\n\n\nComprimento do dente (mm)\n8,0±2,7\n13,2±4,5\n-5,3\n-3,17\n-8,8; -1,7\n0,0064\n\n\n\n1 Média ± DP\n\n\n2 Teste t com correção de Welch\n\n\nAbreviação: IC = Intervalo de Confiança\n\n\n\n\n\n\n\n\nEste resultado pode ser interpretado da seguinte maneira:\nOs resultados indicam que o comprimento médio do dente foi significativamente maior nas cobaias que receberam suco de laranja (13,2 ± 4,5 mm) em comparação com aquelas que receberam ácido ascórbico (8,0 ± 2,7 mm). A diferença média entre os grupos foi de -5,3 mm, com um intervalo de confiança de 95% de -8,8 a -1,7 mm. Esse resultado foi estatisticamente significativo (t = -3,17, p = 0,006), conforme o teste t com correção de Welch, sugerindo que o tipo de suplemento influencia o comprimento do dente."
  },
  {
    "objectID": "blog_posts/teste - qui quadrado/qui-quadrado.html",
    "href": "blog_posts/teste - qui quadrado/qui-quadrado.html",
    "title": "Teste Qui-quadrado",
    "section": "",
    "text": "O teste Qui-quadrado (\\(\\chi^2\\)) é um método da estatística utilizado para responder os seguintes tipos de pergunta.\n\nExiste Associação entre 2 variáveis categóricas?\n\n\nAs frequências observadas em 1 variável categórica são iguais as frequências teóricas esperadas?\n\nVariaveis categóricas são aquelas que representam qualidades, categorias, grupos ou classificações, podendo ou não ter uma ordem. Alguns exemplos: gênero (Homem, Mulher, …), grau de instrução (Fundamental, Médio, Superior,…), presença de doença (Sim, Não).\nO teste trabalha comparando as frequências observadas, que são os dados reais coletados, com as frequências esperadas, que são as frequências estimadas sob a hipótese nula.\nO teste calcula uma medida do quão distante as frequências observadas estão das frequências esperadas. Essa diferença é traduzida em um valor de \\(\\chi^2\\), que indica o desvio entre os dados e o esperado.\nSe a diferença entre as frequências observadas e esperadas for muito grande, isso pode significar que existe associação entre as variáveis (no caso da análise de associação) ou que as proporções observadas das categorias não seguem as proporções esperadas (no caso do teste de aderência).\nPara ilustrar esse método, suponha um estudo de ensaio clinico aleatorizado realizado para avaliar um novo medicamento.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResposta ao medicamento\n\n\n\n\n\n\n\n\n\n\nMelhora\n\nTotal\n\n\nSim\nNão\n\n\n\n\nMedicamento\n\n\n\n\n\n\n\n\n    Novo\n40\n20\n60\n\n\n    Placebo\n16\n48\n64\n\n\nTotal\n56\n68\n124\n\n\n\n\n\n\n\nDependendo do tipo de experimento ou investigação que está sendo realizado, a formulação estatística das hipóteses pode variar mas no geral a aplicação do teste qui-quadrado é a mesma para todos os estudos envolvendo duas variáveis categóricas.\nPara esse exemplo em especifico podemos estabelecer as seguintes hipóteses\n\n\\(H_0\\): Prob(Melhora no grupo do medicamento NOVO) \\(=\\) Prob(melhora no grupo que tomou o PLACEBO)\n\\(H_1\\): Prob(Melhora no grupo do medicamento NOVO) \\(\\neq\\) Prob(melhora no grupo que tomou o PLACEBO)\n\n’\n\n\n\n\n\n\n\n\nn\nstatistic\np\ndf\nmethod\np.signif\n\n\n\n\n124\n21.70868\n3.17e-06\n1\nChi-square test\n****\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\ny\nobserved\nprop\nrow.prop\ncol.prop\nexpected\nresid\nstd.resid\nchi\nchi_pdr\n\n\n\n\nNovo\nSim\n40.00\n0.32\n0.67\n0.71\n27.10\n2.48\n4.66\n6.14\n1.12\n\n\nPlacebo\nSim\n16.00\n0.13\n0.25\n0.29\n28.90\n−2.40\n−4.66\n5.76\n0.52\n\n\nNovo\nNão\n20.00\n0.16\n0.33\n0.29\n32.90\n−2.25\n−4.66\n5.06\n−0.57\n\n\nPlacebo\nNão\n48.00\n0.39\n0.75\n0.71\n35.10\n2.18\n4.66\n4.74\n−1.07\n\n\n\n\n\n\n\nA partir do resultado do teste Qui-quadrado de independência podemos rejeitar a hipótese nula de que que não há associação entre melhora e tipo de medicamento ( \\(Q_p=21,7;p&lt;0,0001\\) ), o que nos permite afirmar que, para este ensaio, a incidencia de melhora positiva foi maior no grupo que tomou o novo medicamento em comparação com o grupo controle que tomou o placebo.\nO teste qui-quadrado apenas testa se existe associação, mas não é capaz de indicar como é essa associação. Para isso é necessário calcular uma Medida de Associação, tema que será melhor explorado em outro momento."
  }
]